## 정오행렬 기반 성능 평가 지표

- **정분류율, 균형정확도, F1-지표**

학습데이터에 대해 100% 정확한 모형을 만다는 것은 좋지 않다.

왜냐하면 모델이 학습 데이터에 존재하는 노이즈까지 외우게 되어 새로운 데이터에 적용할 경우 예측 성능이 저하되는 과적합(Overfitting) 현상이 발생할 수 있기 때문이다.

#### Q. 과적합 현상이 발생하지 않고, 새로운 데이터에 대한 예측 성능이 좋은 모델을 만들기 위해서는 어떻게 해야 할까?

- 분류 또는 회귀 문제를 풀 수 있는 다양한 알고리즘이 존재하고, 

- 어떤 알고리즘은 최적의 하이퍼파라미터 설정이 필요하다.

- 문제 해결에 대한 **최적의 알고리즘 선택**하고 **최적의 하이퍼 파라미터를 설정**하기 위해서 **개별 모델을 <u>동등한 조건</u>에서 평가할 필요**가 있다.
    - 동등한 조건 : 모든 알고리즘이 보지 못한 새로운 데이터
    
    
- 이를 위해 전체 데이터셋을 <u>학습에 사용하는 학습데이터</u>와 <u>모델의 성능을 확인하는 검증, 테스트 데이터</u>로 분할하여 성능 평가를 수행해야 한다. 
    - 검증 데이터 : 다양한 파라미터 조합 중 최적의 파라미터 찾는데 주로 사용
    - 테스트 데이터 : 여러 알고리즘 중 최적의 알고리즘을 찾는데 주로 사용

## 성능 평가 : 정오행렬 기반의 성능 평가 지표

### 정오 행렬(Confusion Matrix)
- 실제 범주와 예측된 범주를 이용하여 생성한 C by C 행렬
- C : 범주의 수
- 2범주 분류 문제에서 정오행렬의 Positive(1범주)는 분석가가 더욱 관심을 두는 범주로 정의하는 것이 일반적이다.
- 예시 
    - 제조 공정 데이터 분석에서의 불량 제품
    - 의료 분야에서의 특정 질병 확진
    - 마케팅 캠페인에 대한 반응 고객 
- 범주에 대한 중요도의 차이가 없을 경우 임의의 한 범주를 Positive Class로 설정(성별 분류, 이미지 기반의 개/고양이 분류 등)

본 포스팅에서 사용할 예시는 체지방률을 사용한 성별 분류이며, 체지방률이 20보다 크면 여성으로, 작으면 남성으로 분류한 것이다.
![JPG](/assets/images/정오행렬.JPG)

#### < 얼마나 잘 맞췄는지 : 민감도, 특이도 >

#### 1. 민감도 or True Positive Rate(TPR)
- 실제 Positive Class 객체들 중에서 모델에 의해 Positive Class로 예측된 비율
- n11/(n11+n10) = 4/5 = 0.8

#### 2. 특이도 or True Negative Rate(TNR)
- 실제 Negative Class 객체들 중에서 모델에 의해 Negative Class로 예측된 비율 
- n00/(n01+n00) = 3/5 = 0.6

<br>

#### < 얼마나 못 맞췄는지 : 누락, 오경보 >
#### 3. 누락(Miss) or False Negative Rate(FNR)
- 실제 Positive Calss 객체 중에서 Negative Calss로 잘못 예측된 비율
- n10/(n11+n10) = 1/5 = 0.2

#### 4. 오경보(False Alarm) or False Positive Rate(FPR)
- 실제 Negative Class 객체 중에서 Positive Class로 잘못 예측된 비율
- n01/(n01+n00) = 2/5 = 0.4

#### ★5. 정분류율(Accuracy : 정확도)
- 전체 객체들 중 맞게 예측된 비율
- (n11+n00)/(n11+n10+n01+n00) = 7/10 = 0.70
- 머신러닝을 모르는 일반인들도 가장 쉽게 사용하는 평가 지표

#### 6. 오분류율(Misclassification Error)
- 전체 객체들 중 잘못 예측된 비율
- (n10+n01)/(n11+n10+n01+n00) = 3/10 = 0.3

Q. 정분류율이 높으면 항상 좋은 모형인가?
- 예시 : 제조업에서의 불량 제품 탐지 모형
- 총 1000개의 제품. 불량률 1%(Class Imbalanced). 분석가 A씨는 99% 정확도를 자랑하는 불량탐지 모델을 만들고 기뻐했지만
- 불량을 하나도 잡아내지 못하는 쓸모없는 모형이었다.
![JPG](/assets/images/분석가A씨.JPG)

위의 예시처럼 클래스 항목이 불균형한 경우에는 정확도(Accuracy)의 평가 지표로는 모델의 성능을 신뢰할 수 없다.

클래스의 불균형 문제에 따른 평가 지표들을 살펴보자. 

#### < 정분류율의 단점을 고려한 성능 평가 지표 >
- 균형 정확도, 재현율, 정밀도, F1-지표

#### ★7. 균형 정확도(Balanced Correction Rate, BCR) 
- 민감도(TPR)와 특이도(TNR)를 고려한 성능 평가 지표
![JPG](/assets/images/균형정확도.JPG)

#### 8. 재현율(Recall) = TPR
- 실제 Positive Class 객체들 중에서 Positive Class로 맞게 예측된 비율
- n11/(n11+n10) = 4/5 = 0.8

#### 9. 정밀도(Precision)
- 모델이 Positive Class로 예측한 객체들 중에서 실제 Positive Class인 비율
- n11/(n11+n01) = 4/6 = 0.67

precision과 recall은 보통 반대되는 수치를 가진다.(Trade-Off)

그래서 높은 precision이나 recall은 실제 활용 도메인이나 필요 상황에 맞는것을 택할 수 있다.

혹은 Precision과 Recall 지표의 황금비율을 찾도록 도와주는 F1-지표를 사용할 수 있다.

#### ★10. F1-지표(F1-Measure)
- 재현율과 정밀도의 조화 평균
- 1이 될 때 최적의 Precision과 Recall을 의미하고, 0이 최악을 의미한다.
- Positive Class에 중점 $\rightarrow$ 여성(F)을 잘 맞추면 점수 올라감
![JPG](/assets/images/F1지표.JPG)

앞서 분석가 A씨가 만든 모델을 각각의 지표로 성능 평가를 수행해보면
- 정분류율 : 99%
- 균형정확도 : 0
- F1-지표 : 0

### 3개 이상의 범주 분류
- C by C 정방행렬
- 정오 행렬의 대각 성분은 정분류된 Case, 비대각 성분은 오분류된 Case
- **정분류율, 균형정확도, Marco F1-Score 산출 가능**
![JPG](/assets/images/정분류율, 균형정확도.JPG)
![JPG](/assets/images/범주3의 F1지표.JPG)
micro F1 : 각 범주별 F1-지표

### 상황별 대표 분류 평가 지표 가이드라인
![JPG](/assets/images/상황별 평가지표.JPG)
