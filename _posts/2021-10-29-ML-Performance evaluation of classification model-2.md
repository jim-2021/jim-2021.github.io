## AUROC 및 오분류 비용

## AUROC

### 정오행렬의 특징 : 분류 기준값 반드시 필요

- 일반적인 분류 알고리즘은 Positive Class에 속할 확률(또는 우도)값을 먼저 계산한 뒤 분류 기준값(cut-off)와의 비교를 통해 특정 범주에 할당한다.
- 앞선 포스팅에서 체지방률을 사요한 성별 분류 예시에서는 20을 기준으로 이보다 높으면 여성, 낮으면 남성으로 분류했다.
- 그렇다면 20이 아닌 다른 값을 분류 기준값(cut-off)으로 사용하면 어떻게 될까?

#### 분류 기준값(cut-off)에 따른 정오행렬의 변화
- 일반적으로 분류 알고리즘은 특정 범주에 속할 확률(probability)이나 우도(likelihood)값을 생성한다.
- 동일한 확률값 하에서도 cut-off를 어떻게 설정하는가에 따라서 분류 성능이 크게 좌우되는 상황이 발생할 수 있다.
- **분류 알고리즘 간의 정확한 비교를 위해서는 <u>cut-off에 독립적인 측정 지표</u>가 필요하다!**

### Area Under Peceiver Operating Characteristic Curve (AUROC)

#### <예시>
- 제품의 불량을 판정하는 문제
    - 총 1000개의 제품
    - 20개의 제품이 불량(불량 비율 : 0.2)
    - Label : 1(NG), 0(G)
    - 분류 알고리즘에 의해 추정된 불량 확률(P(NG))과 실제 범주 레이블(불량=1)
        - P(NG) : 모든 알고리즘 동일
<img src = "./image/분류모형성능평가/표.JPG" width="70%">

- 분류 기준값이 달라짐에 따라 정오행렬이 변화하고, 성능도 달라진다.
<img src = "./image/분류모형성능평가/cutoff변화에 따른 성능지표 변화.JPG" width="60%">
- 특정 알고리즘이 산출한 동일한 확률값들에 의해서 cut-off가 달려졌기 때문이다! (확률값이 달라지지x)
- 동일한 확률값인데 성능이 다르게 된다!

#### ROC Curve 생성 절차
1. 모든 개체를 P(interesting class)를 기준으로 내림차순 정렬하고,
2. 가능한 모든 cut-off 경우에 대해 True Positive Rate(TPR)와 False Positive Rate(FPR)를 계산한 후
3. X축이 False Positive Rate, Y축이 True Positive Rate가 되는 2차원 그래프 그리기

- 100개의 Class(제품) $\rightarrow$ 101개의 cut-off 생성 가능

예를 들어, 3번째 cut-off의 경우 2번과 3번 사이에 위치하고, 이때의 TPR은 0.1, FPR은 0이다. 
<img src = "./image/분류모형성능평가/3번째 cutoff.JPG" width="60%">

2. 모든 가능한 cut-off애 대해 TPR과 FPR 산출
<img src = "./image/분류모형성능평가/cutoff에 대한 TPR, FPR 산출 표.JPG" width="50%">

3. ROC Curve 그래프 그리기
<img src = "./image/분류모형성능평가/roc커브.JPG" width="60%">

#### ROC Curve와 Cut-off와의 관계
- cut-off를 타이트하게 잡느냐, 느슨하게 잡느냐에 따라서 모든 가능한 TPR과 FPR의 조합 중 한 점으로 표현된다.
- 이 점의 값을 기준으로 해서 성능 지표들(정분류율, 균형정확도, F1-지표)의 값이 도출된다.
- 즉, 동일한 알고리즘이라고 해도 cut-off가 다르면 성능 지표 값이 달라질 수 있다.
- $\Rightarrow$ 정오행렬의 문제점
<img src = "./image/분류모형성능평가/cutoff와 roc curve 관계.JPG" width="50%">

#### AUROC : ROC Curve 아래의 면적
- **정오행렬과 달리 AUROC는 모델의 예측 결과가 주어지면 단 1개의 성능 지표 값이 도출된다. $\Rightarrow$ 보다 공정한 평가 지표!**
- 이상적인 분류기는 1의 값을 갖고, 무작위 분류기는 0.5의 값을 가진다. $\rightarrow$ 면적이 클수록 좋은 모델!
- **cut-off에 독립적인 알고리즘 성능 평가 지표로 사용될 수 있다.**
<img src = "./image/분류모형성능평가/auroc 그래프.JPG" width="50%">

## 오분류 비용

경제적 가치로 성능평가를 환산한 것이다.(비즈니스적 관점)

한 조직에는 여러 업무를 하는 사람들이 모여있기 때문에 정확도 지표만 가지고 의사소통하는 것보다 경제적 관점에서 봤을 때 어떤 이득이 있는지를 기준으로 설득한다면 의사소통이 더욱 수월해질 것이다.

이에 앞서 살펴본 성능평가 지표를 경제적 가치로 환산하는 방법에 대해 알아보도록 하자.

### 비대칭 오분류 비용(Asymmetric misclassification costs)
- 많은 비즈니스 문제에서는 한 범주를 정확하게 판별하는 것이 다른 범주를 정확하게 판별하는 것보다 중요하게 취급된다.
    - 질병 진다. 세금 사기, 신용카드 사기, 마케팅 프로모션 응답 예측 등
- 이러한 경우, 전체 집합에 대한 오분류가 증가하더라도 **주요 범주에 대한 정확도를 높이는 것이 효과적일 수 있다.**
    - 특정 범주에 대한 <u>오분류 비용</u>이 다른 범주보다 큰 경우
    - 특정 범주에 대한 <u>정분류 효과</u>가 다른 범주보다 큰 경우

- 오분류 비용 metrix
    - 누락(Miss) 비용 : 불량 제품을 정상 제품으로 잘못 판별하여 제품이 출시될 경우 제품 교환 및 고객 클레임 응대 비용 등
    - 오경보(False Alarm) 비용 : 정상 제품을 불량으로 잘못 판별하여 해당 제품을 판매하지 못함으로써 발생하는 손실

- 예시 : 공정 데이터 기반의 제품 불량 탐지 모형
    - 총 1000개의 제품, 990개 정상, 10개 불량
    - 두 가지의 모델 비교
<img src = "./image/분류모형성능평가/오분류 비용.JPG" width="70%">

두 모델의 경제적 가치를 살펴보면 

- 첫 번째 모델의 경제적 가치는 18,800,000
- 두 번째 모델의 경제적 가치는 19,300,000(1번 모델 대비 +500,000)

**$\Rightarrow$ 모델의 비대칭 오분류 비용을 통해 경제적 가치를 파악할 수 있다.**
