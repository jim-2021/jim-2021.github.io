## 가지치기

의사결정나무에서의 분류 예측은 **말단 노드에 속한 객체들의 비율**을 통해 판정을 내려서 결정된다. 

아래 그림과 같이 새로운 데이터(빨간 동그라미)가 저 공간에 들어갔을 때 이 데이터는 x로 분류될 것이다. 그리고 이때 비율의 기준(cut-off)은 설정하기 나름이지만 보통 0.5로 사용한다. cut-off가 0.5라는 것은 x가 절반 이상이 있으면 새로운 데이터는 x로 분류한다는 뜻이다.
<img src = "./image/의사결정나무/예측 예시 설명.JPG" width="50%">

### 재귀적 분기는 모든 말단 노드의 순도가 100%일 때 학습이 종료된다.(Full Tree)

$\Rightarrow$ 학습데이터의 모든 데이터를 정확하게 분류한다.

재귀적 분기의 문제점 : 재귀적 분기는 과적합의 문제가 있고, 결국 새로운 데이터에 대한 예측 성능 저하의 위험을 안고 있다.

- 의사결정나무의 노드 수가 증가할 때(분기) 처음에는 데이터에 대한 오분류율이 감소하나, 일정 수준 이상이 되면 오분류율이 증가하는 현상이 발생한다.

- 이러한 문제점을 해결하기 위해 재귀적 분기를 완료한 뒤(Full Tree를 생성) 적절한 수준에서 말단 노드를 결합하는 가지치기를 수행한다.
- 사후적 가지치기

### 가지치기(Pruning)

- 테스트 데이터에 대한 오분류율이 증가하는 시점에서 가지치기를 수행하여 Full Tree에 비해 구조가 단순한 의사결정나무가 생성된다.

#### 비용복잡도(Cost Complexity) : 최적의 의사결정나무 구조 선택하기
- 비용복잡도가 낮을수록 우수한 의사결정나무이다.
<img src = "./image/의사결정나무/비용 복잡도 식.JPG" width="30%">
- CC(T) : 의사결정나무의 비용복잡도
- Err(T) : 검증데이터에 대한 오분류율
- L(T) : 말단 노드의 수 (구조 복잡도)
- $\alpha$ : Err(T)와 L(T)를 결합하는 가중치(사용자 부여, 디폴트값이 존재)
    - Err(T)는 0~1의 범위를 가지고, L(T)는 자연수이기 때문에 범위가 맞지 않아서 $\alpha$를 곱해줘야 한다.
  
  
- 말단 노드 수가 같다면 검증 데이터셋 오류율이 낮은 Tree를 선택
- 동일한 검증 데이터셋 오류율이라면 말단 노드 수가 적은 Tree를 선택

### 사후적 가지치기 절차
- Full Tree를 생성한 뒤 다시 최적의 구조를 찾아 의사결정나무를 단순화 시키는 방법

1. 재귀적 분기를 통한 Full Tree 생성

2. 가지치기 : 분기를 취소해서 상위 2개의 노드로 병합
    - 여러 단계를 통해 수행
    
3. 가지치기 수행 전(좌측)-후(우측) 비교
<img src = "./image/의사결정나무/가지치기 완료.JPG" width="70%">

### 사전적 가지치기(Pre-Pruning)

- Full Tree를 생성하지 않고 적절한 시점에서 더 이상 분기하지 않도록 제약조건을 부여한다. 
- 제약조건 예시
    - 분기 전후 정보획득(Information Gain)의 최저 기준
    - ★분기 대상이 되는 노드에 속하는 최소 객체 수 
    - 의사결정나무가 가질 수 있는 최대 깊이 
    
- 아래 그림에서 **분기 대상이 되는 노드에 속하는 최소 객체 수를 3으로 설정하면**
<img src = "./image/의사결정나무/가지치기 조건.JPG" width="40%">
- 오른쪽 분홍색 영역은 데이터가 혼재되어 있지만 기준을 충족하지 못하여(객체 2개) 더 이상 분기되지 않는다.
- 왼쪽 초록색 영역은 데이터가 혼재되어 있고, 기준을 충족하기 때문에(객체 3개) 분기 가능하다.

### 의사결정나무 예시
<img src = "./image/의사결정나무/의사결정나무 예시 그림.JPG" width="60%">

## 의사결정나무 : 회귀

회귀의 경우 의사결정나무를 어떻게 사용할까?

해당 노드에 속하는 모든 개체의 종속변수 값의 평균으로 예측한다.

### 회귀모형에서의 불순도 측정
- 중심을 기준으로 얼마나 퍼저 있는가(분산)


### 의사결정나무 요약

#### 장점
- 예측에 대한 설명을 제공할 수 있다.
- 변수 선택 과정이 자동적으로 수행된다.
- 결측치가 존재해도 모델 구축이 가능하다.

#### 단점
- 한 번에 하나의 변수만 고려하므로 변수 간 상호작용을 파악하기 어렵다.
