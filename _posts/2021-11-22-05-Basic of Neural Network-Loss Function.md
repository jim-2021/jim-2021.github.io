## 손실함수(Loss Function)

<img src = "./image/손실함수/IMG_1191.JPG" width="75%">

딥러닝에서 학습은 weight 즉, 가중치 파라미터는를 업데이트하는 과정이다. 이때 weight는 현재의 상태를 표현하는 어떠한 '지표'를 가장 좋게 만들어주는 방향으로 업데이트된다. 여기서 말하는 '지표'가 바로 손실함수이다.

**손실함수를 통해 출력한 y값과 정답 사이의 loss 즉, 오차를 구해서 이 오차가 줄어드는 방향으로 weight를 업데이트 해준다.**

학습 과정에서 학습의 길잡이로서 손실함수가 꼭 필요하다.

딥러닝에서는 손실함수로 보통 평균제곱오차(MSE)와 교차 엔트로피 오차(CEE)를 많이 사용한다.

- 신경망 학습 : 현재의 상태를 표현하는 '지표'를 가장 좋게 만들어주는 가중치 파라미터를 탐색하는 작업 
- 지표 : 손실함수(Loss/Cost Function)
- 손실함수로는 보통 평균제곱오차(MSE)와 교차 엔트로피 오차(CEE)를 많이 사용한다.

### 손실함수  vs 성능 척도

#### 손실함수 (Loss Function)

- 학습 과정에서 알고리즘이 아직 **얼마나 못 하는지**를 표현한다.
- 보통 미분 가능한 함수를 사용한다.
    - 손실함수는 최적화 이론에서 (loss를) 최소화하고자 하는 함수이고,
    - 미분을 기반으로 하는 최적화 방법이 많음
- 또 다른 이름으로 목적 함수, 비용함수, 에너지 함수 등으로 불린다.
- 학습 과정에서 중요한 역할을 한다.

#### 성능 척도 (Performance measure)

- 학습이 완료된 알고리즘의 성능을 측정하는 지표이다.
- 정량적으로 **알고리즘을 비교/평가**하기 위함이다.
- 학습 과정에서는 사용되지 않는다.
- '비즈니스 목표'와 연관이 크다.

### 평균제곱오차 함수 (MSE)

- 가장 기본적인 손실함수이다.
- 오차가 커질수록 손실함수가 빠르게 증가한다. (제곱이기 때문에)
- 회귀(Regression)에 많이 사용

<img src = "./image/손실함수/IMG_1193.JPG" width="30%">
<img src = "./image/손실함수/IMG_1192.JPG" width="50%">


### 평균제곱오차 함수 예제(회귀)
<img src = "./image/손실함수/IMG_1194.JPG" width="80%">

$\Rightarrow$고양이의 길이와 체중의 오차를 **종합적으로** 보고 줄여나갈 수 있다.

### 평균절대오차 함수 (MAE)

- Mean absolute error
- 오차가 커져도 손실함수가 일정하기 증가한다.
- Outlier에 강하다.
- 통계적으로 중간값(median)과 연관이 있다.
- 회귀(Regression)에 많이 사용

### 교차 엔트로피 오차 (CEE)

- Cross entropy error
- Softmax 출력($\tilde{y_i}$)과 원-핫 인코딩($y_i$)을 비교한다.
    - $y_i$ : 학습 데이터 정답의 i번째 요소(원-핫 인코딩)
    - $\tilde{y_i}$ : 학습 데이터 입력으로 추정한 출력의 i번째 요소(0~1 사이 값)
- 원-핫 인코딩으로 인해 정답인 클래스에 대해서만 오차를 계산한다.(정답 빼고는 다 0)
- 정확히 맞추면 오차가 0, 틀릴수록 오차가 무한히 증가한다.

<img src = "./image/손실함수/IMG_1196.JPG" width="30%">
<img src = "./image/손실함수/IMG_1195.JPG" width="50%">


### 교차 엔트로피 오차 예제(다중 분류)
<img src = "./image/손실함수/IMG_1197.JPG" width="70%">

- 오차를 내는 과정에서는 정답 클래스만 비교하지만, 다중 클래스 분류의 활성함수인 Softmax로 인해 **다른 클래스에 대한 학습에도 영향을 준다.**
