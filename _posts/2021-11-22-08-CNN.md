### 머신러닝과 딥러닝 차이
- 딥러닝에서는 feature extraction 자동

- 첫 번째 CNN
- LeNet-5
- AlexNet : CNN(딥러닝)의 시대가 왔다~!

Topographical mapping in the cortex: 
nearby cells in cortex represent
nearby regions in the visual fields

특정 패턴을 인식할 때 뇌의 특정 부분이 활성화가 많이 되는 규칙을 뇌과학적으로 밝혀냈다.

뇌가 이미지를 인식할 때 뇌의 특정 파트가 이미지의 특정 정보, 패턴을 인식한다.

이것에서 착안하여 만들어진 것이 CNN(Convolution Kernel이 역할)

## CNN을 어디에 쓰는가?

**CNN are everywhere!**

- Classification
- Retrieval(유사이미지 검색)
- Object Detection
- Semantic Segmentation
- Image Captioning : 이미지와 텍스트의 연결
- etc

## CNN : Convolutional Neural Network

- CNN 구조 이미지
![JPG](/assets/images/CNN 흐름.JPG)

**CNN의 중요한 Concept : 데이터가 어떻게 들어가느냐!**

### Fully Connected Layer

CNN이 아닌 Fully Connected Layer의 경우 데이터가 어떻게 들어가는지 살펴보자.

- < CIFAR10 > : 60000장의 이미지, 10 $\rightarrow$ classes 분류 문제

![JPG](/assets/images/input flatten.JPG)

- 위 사진에서 32x32x3의 이미지를 3072x1로 펴준(flatten) 후에 input으로 넣어준다. 즉 input vector로 만들어주는 것이다.
- 그리고 3072개의 숫자가 10개로 변환되는 행렬 연산을 한다.
- 행렬 연산으로 나온 10개의 scores를 10개의 target과 비교해서 loss값을 구한다.


- 참고) 이미지 데이터
    - 흑백 이미지 데이터의 경우 ``32x32``(픽셀개수)사이즈로 되어 있다. 여기에 색깔 정보인 RGB가 추가되면 컬러 이미지가 된다. 즉, 컬러 이미지 데이터는 ``32x32x3``사이즈로 되어 있는 것이다. 
    - 여기서 ``RGB(3 channel)``는 정보채널의 의미를 담고 있다. <u>이미지와 관련된 색상 정보</u> 혹은 <u>이미지에 관련된 여러 정보를 얼마나 주는냐</u>에 대한 정보이다.


- 참고) RGB
    - 24bits로 표현되는데, 8bits로 끊어서 각각 R, G, B 값을 가진다.
    - 하나에 1bytes. 즉 숫자값을 가지는데, **0~225의 숫자로 RGB값을 표현한다.**
    
**$\Rightarrow$ CNN은 데이터를 넣어줄 때, flatten해서 vector로 만들지 않고 이미지 그대로(32x32x3) 넣어줘도 된다.**

### < Convolution Layer >

CNN은 이미지 그 자체의 정보를 인식한다.
 
= 2D 이미지 자체의 "spatial locality"를 학습한다. 
 
32 x 32 x 3 image $\rightarrow$ **preserve spatial structure** 

![JPG](/assets/images/input filter.JPG)

#### 32x32x3 image
- 이미지를 일자로 펼치면 사물의 패턴을 파악할 수 없다. CNN은 2D 이미지를 그대로 사용해서 이미지 자체의 중요한 feature를 뽑는다.
- 중요한 feature를 뽑는다는 것은 2D 이미지의 특정 영역에 대한 정보를 뽑는다는 것을 의미한다. 
- 그렇다면 정보를 어떻게 뽑을 것인가? 즉 **어떤 패턴을, 어떻게 뽑을 것인가?**
- 이러한 feature 추출은 학습에서 이루어진다.(하이퍼 파라미터 $\rightarrow$ 학습에 대한 설명은 뒤에서 하도록 하겠다.)
- 여기서 딥러닝과 머신러닝의 차이점을 확인할 수 있다. <u>딥러닝은 feature 추출을 자동화</u>한다는 것이다.
- Convolution 연산 $\Rightarrow$ feature 추출

#### 5x5x3 filter
- filter = kernel : 2D 이미지 상에서 특정 패턴을 학습하는 단위
- filter를 몇 개, 얼마나, 어떤 사이즈을 쓰느냐에 따라 이미지에서 어떤 패턴을 파악할지 정하게 된다.
- filter의 개수 : 파악하고 싶은 패턴의 개수(하이퍼 파라미터)
- ``32x32x3`` image에서 ``3``이 색깔 정보를 나타내듯이(사진 하나가 숫자 3개로 구성), 마찬가지로 filter의 ``5x5x3``에서 ``3``도 색깔 정보이다. 
    - **이전 layer에서 넘어온 정보를 전부 사용해야 하기 때문에 이전 layer와 channel(depth) 수를 맞춰줘야 한다. $\Rightarrow$ 연산 가능, 의미 있음**

#### Convolution 연산

- **2D 이미지의 특정 영역에서의 Convolution 연산을 통해 하나의 숫자를 뽑아낸다. $\Rightarrow$ feature 추출**
- 가장 중요한 2가지
    1. filter를 지나면 숫자 1개가 나온다. $\Rightarrow$ feature 추출
    2. channel의 수를 맞춰줘야 한다.(input의 경우는 거의 다 3이다.)

![JPG](/assets/images/convolve 연산.JPG)

![JPG](/assets/images/내적.JPG)

- filter와 image의 5x5x3 조각을 내적하면 숫자 1개가 나온다. 
- filter size 5x5x3 : **75-dimensional dot product(75차원 길이의 내적)** + bias $\Rightarrow$ 76번의 연산
- 결과값 : **$w^Tx+b$**

#### activation map
- filter를 전체 image에 convolve(연산)해서 activation map을 만든다.
- **filter 1개 $\rightarrow$ activation map 1개**. 여러 개의 activation map 나온다.(channel과 관계x - channel정보를 다 더해줬으니까)
- activation map의 크기는 filter size와 stride의 정보를 통해 자동으로 연산되서 나온다.
    - stride : slide할 때 움직이는 칸 수. 크게 하면 출력의 크기가 줄어든다.
    - 식 : (N - F) / stride + 1 $\Rightarrow$ Conv layer 지났을 때의 activation map 크기
    - 위 식의 값이 float면 에러!
- 예를 들어, filter(5x5x3)가 6개라면 6개의 activation maps을 갖게 된다.(filter 개수 : 하이퍼파라미터)
- activation maps는 다음 layer의 input이 된다.
- **다음 layer의 channel(depth) 개수는 이전 layer의 filter 개수와 같다.**

![JPG](/assets/images/conv 여러번.JPG)

- ReLU : non-linear 만들기 위함.

### Zero Padding

![JPG](/assets/images/zero pad.JPG)

- 예를 들어, 7x7 input, **3x3 filter, stride 1, zero padding 1**일 경우,
- output의 size는 어떻게 될까? : **7x7 output. input size와 동일**하다.

#### Zero Padding을 하는 이유는 무엇일까?

- 여러 개의 Conv layer를 지나다 보면 32 -> 28 -> 24 ... 이미지의 사이즈가 빠르게 줄어들는데, 이는 학습에 좋지 않다.
- 그렇기 때문에 filter size를 줄이지 않고도, 이미지 사이즈가 너무 많이 줄어들지 않았으면 할 때 사용한다.
- Zero Padding 장점 (stride 값과 동일 : 사이즈 유지)
    1. 이미지 사이즈 조절이 가능하다. $\Rightarrow$ 사이즈 유지 가능
    2. 이미지의 가장자리 정보를 학습한다. (다 0이니까 여기가 가장자리인지 알 수 있음)
- 어떻게? boundary에 0을 넣어서 input 사이즈가 커지도록 한다. 


- 일반적으로, <u>stride 1</u>, <u>FxF filter</u>, <u>(F-1)/2의 zero-padding</u>이 있는 CONV layer를 사용한다.
    - F = 3 $\rightarrow$ zero pad with 1
    - F = 5 $\rightarrow$ zero pad with 2
    - F = 7 $\rightarrow$ zero pad with 3
    
#### 이미지를 덜 줄이는 방법
1. 3x3 filter
2. stride 작게 하기
3. zero padding

#### Examples Quiz
- input volume 32x32x3, 10 5x5 filters with stride 1, pad 2
- output volume size ? 
- 답 : (32 + 2x2 - 5)/1 + 1 = 32 $\Rightarrow$ **32 x 32 x 10**

### < Pooling layer > 

- 일종의 filter이다.
- 이미지에 있는 'downsampling' task를 표현한다.
- 이미지의 크기를 줄이고 관리 용이성을 높인다. (이미지가 너무 크면 연산이 많아진다.)
- 각 activation map에 대해 독립적으로 작동한다.

![JPG](/assets/images/pooling.JPG)

- Convolution Layer와의 차이점
    - Convolution Layer에는 연산, weight가 있어서 학습이 이뤄지지만, <u>pooling에서는 학습 이뤄지지 않는다.</u>
- Pooling의 2가지 방법
    - Max $\rightarrow$ 사용 多
    - Average

### Max Pooling

![JPG](/assets/images/MaxPooling.JPG)

- 겹치지 않도록 filter 개수만큼 stride를 해준다.

1. 두드러지는 특징을 추출한다.(경계선, 튀어나온 부분 etc)
    - activation map에서 특정 영역의 가장 큰 값을 추출한다.
    - 유의미한 feature들만 뽑아서 넣기 때문에 학습이 잘 된다.
2. 연산량이 감소한다.(이미지 사이즈 1/4로 감소)

- 같은 크기의 filter여도 pooling에 의해 작아진 activation map에 적용되면 filter가 원본 이미지에서 차지하는 범위가 넓어진다.
- 이 범위를 Receptive Field라고 한다.
- 즉 큰 filter를 사용해서 연산량을 늘리는 대신 이미지의 크기를 줄이고 같은 filter를 사용하기 위함이다.

### 전체적인 CNN 구조

![JPG](/assets/images/CNN 전체구조.JPG)

### < FC layer (Fully Connected Layer) >

- Contains neurons that connect to the entire input volume, as in ordinary Neural Networks
- CIFAR10 데이터를 가지고 있고, 이는 10개의 class로 분류하는 다중분류 문제이다.

여러 Conv, ReLu, Pooling을 지나와서 나온 activation maps를 해당 분류 문제에 적용할 수 있도록 10개의 클래스로 만들어주는 부분이다.

10차원 vector로 만들어줘야 한다.

어떻게 만들어? 행렬 연산(내적)

이렇게 만든 10차원 vector(숫자 10개)를 softmax function을 사용해서 0~1값으로 정규화 해준다.

output (0.8, 0.1, 0, 0, ..., 0.1) : 확률값처럼 나온다.(전부 더하면 1)

output layer를 target과 비교해서 cross entropy loss를 구한다.

**FC : input image를 고급진 feature vector로 바꿔주는 임베딩**

- 대부분의 CNN에서 파라미터 개수가 가장 많다. weight 몰빵!
- weight matrix 가장 크고, update도 오래 걸린다.

## Gradient update 3가지 규칙 in Conv

### 1. FC (Fully Connected)

연산에 참여한 모든 weight가 그대로 update를 받는다.(loss값을 gradient 방향으로 learning rate만큼 update 받음)


### 2. Pooling

- Max Pooling
- 16개의 activation score $\rightarrow$ 4개만 살아서 넘어간다.
![JPG](/assets/images/MaxPooling.JPG)

- **update도 살아서 넘어온 애들한테만 해준다.(6, 8, 3, 4)** 나머지 애들은 feed forward에 참여를 안했기 때문에 탈락!
- **<u>Max Pooling의 score를 만들었던 Conv Layer의 gradient가 update된다.</u>** (나머지는 gradient값이 0)


### 3. ReLU function

- Positive : x 그대로 gradient update
- Negative : 0 (update 못함)


#### CNN에서는 Max Pooling에 참여하지 못했거나, ReLU로 넘어가지 못한 애들은 gradient가 0이 되서 죽음.. 

$\Rightarrow$ weight updata X 

**"dying gradient"**

## Training
- lecture 6,7에 많이 나옴

**딥러닝에서의 training은 Parameter learning 방법이다.**

![JPG](/assets/images/training.JPG)

### 학습을 위해 현실적으로 알아야 할 것들!

### 1. Epoch & Iteration

#### Epoch 
- 데이터 전체가 학습에 참여하면 1 epoch
- 예를 들어, 데이터가 총 10000개가 있을 때, 모두 학습하면(feed forward, backprop일어나서 update까지 완료) 1 epoch

#### Iteration
- loss updata 횟수
- stochastic의 경우 1 epoch = n iteration 
- mini-batch의 경우 전체 데이터를 mini-batch 사이즈로 나눈 개수 만큼이 1 iteration
- full-batch의 경우 1 epoch = 1 iteration

풀배치를 사용하면 epoch = iteration ??


### 2. Stochastic & mini-batch & full-batch training

**loss 계산 단위 : loss가 update되는 단위**

- 데이터 전체(n개)가 들어가서 loss를 update할 때, 데이터의 개수만큼 loss값이 나온다. 이때 이 loss를 어떻게 update할까?
    1. 데이터 1개씩 loss를 n번 update할 경우 : Stochastic
    2. 데이터 n개를 몇개씩 묶어서 평균내서 loss를 m번 update할 경우 : mini-batch
    3. 데이터 전체를 평균내서 loss를 1번 update할 경우 : full-batch => 평균 loss가 줄어드는 방향으로 학습된다. 훨씬 빠르게 학습 가능.
    
Q. 그냥 전체 데이터를 다 넣어서 full-batch로 하면 되는데, 왜 mini-batch, stochastic으로 해?

- 메모리 때문! **메모리가 충분하다면 full-batch 방향으로** 하는 것이 좋다.(이론상 full-batch가 가장 좋음)
    - 우리가 원하는 것은 전체 데이터에 대해 잘 학습하는 것이기 때문에, 이를 위해서는 데이터 전체에 대한 loss가 주어지는 것이 좋다.
    - 또한 데이터를 하나씩 loss update하면 데이터 하나에 치우쳐서 update가 된다. 이는 update의 전체적인 관점에서 봤을 때 update가 느리고, 학습도 잘 되지 않는다.
    
    
- 그런데 현실적으로 full-batch training은 하기 힘들다. 왜냐하면 메모리가 부족하기 때문이다. 
    - 학습 속도를 빠르게 하기 위해서(매트릭스 연산 효율을 높이기 위해서) local gradient 계산해서 가지고 있는데, 모델이 크면 데이터가 클수록 그만큼 많은 local gradient를 가지고 있어야 하고, 그러면 메모리 소모가 크기 때문이다. 모델이 커지면 Full-batch가 안 들어간다.


- mini-batch 사용 多
    - 2의 거듭제곱 (2 / 4 / 8 / 16 / 32 / 64 / ... / n) for 계산 효율성
    - 메모리 터지기 직전까지 최대한 많이 넣기!

- 참고) local gradient 
    - 학습 속도를 빠르게 하기 위해 feed forward 과정에서 local gradient를 계산해서 가지고 있다. 그런데 이 local gradient는 모델이 크면 데이터가 클수록 메모리를 많이 소모한다. 데이터의 개수만큼 gradient를 들고 있어야 하기 때문이다. 
    - 모델이 커지면 Full-batch가 안 들어간다. 메모리가 충분하지 않기 때문이다.(CPU 기준 메인메모리 : RAM)

### 3. Optimizer

- 하이퍼 파라미터
- local minimun에 갇히는 것을 방지하고 학습을 빠르게 할 수 있도록 한다.
- SGD (Stochastic Gradient Descent), Momentum, **Adam**
- **Adam 사용 多**

